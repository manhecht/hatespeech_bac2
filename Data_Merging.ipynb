{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc19a4b",
   "metadata": {},
   "source": [
    "# Pipeline for Dataset Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2860841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d6aef",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d6df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd + '/data/')\n",
    "datasets = ['germeval2018','germeval2019','hasoc2019','hasoc2020','polly','hatespeech_refugees']\n",
    "formats = [\".txt\",\".csv\",\".tsv\"]\n",
    "#dataset = datasets[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2772421",
   "metadata": {},
   "source": [
    "## Functions for different Dataset-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630da1ca",
   "metadata": {},
   "source": [
    "### Preprocessing GermEval Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ae8e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocessGermEval(dataset):\n",
    "    dataset_dir = data_dir + dataset + \"/\"\n",
    "    if \"germeval\" in dataset:\n",
    "        files = os.listdir(dataset_dir)\n",
    "        df = pd.DataFrame()\n",
    "        if any(\"merged\" in file for file in files): \n",
    "            print(\"already merged\")\n",
    "        else:\n",
    "            for file in files:\n",
    "                for f in formats:\n",
    "                    if f in file:\n",
    "                        file_path = dataset_dir + file\n",
    "                        print(\"Merge file: \" + file)\n",
    "                        df_file = pd.read_csv(file_path, sep='\\t', header = None)\n",
    "                        #if df_file['1'] =\n",
    "                        #display(df_file[600:650])\n",
    "                        df_file = df_file.iloc[:,0:2]\n",
    "                        df_file[2] = dataset\n",
    "                        df = df.append(df_file)\n",
    "            for index, row in df.iterrows():\n",
    "                if row.iloc[1] == 'OFFENSE': row.iloc[1] = '1'\n",
    "                elif row.iloc[1] == 'OTHER': row.iloc[1] = '0'\n",
    "            #display(df)\n",
    "            #df.to_csv(dataset_dir + dataset + \"_merged.csv\", sep =',')\n",
    "            if \"germeval2018\" in dataset: \n",
    "                df_ge18 = df\n",
    "                return df_ge18\n",
    "            if \"germeval2019\" in dataset: \n",
    "                df_ge19 = df\n",
    "                return df_ge19   \n",
    "    else:\n",
    "        print(\"This function can only preprocess GermEval datasets\")\n",
    "                    \n",
    "#preprocessGermEval(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91dfad",
   "metadata": {},
   "source": [
    "### Preprocessing Hasoc Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cea2213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessHasoc(dataset,delimiter):\n",
    "    dataset_dir = data_dir + dataset + \"/\"\n",
    "    if \"hasoc\" in dataset:\n",
    "        files = os.listdir(dataset_dir)\n",
    "        df = pd.DataFrame()\n",
    "        if any(\"merged\" in file for file in files): \n",
    "            print(\"already merged\")\n",
    "        else:\n",
    "            for file in files:\n",
    "                for f in formats:\n",
    "                    if f in file:\n",
    "                        file_path = dataset_dir + file\n",
    "                        print(\"Merge file: \" + file)\n",
    "                        df_file = pd.read_csv(file_path, sep=delimiter, header = None)\n",
    "                        df_file = df_file.replace('\\n','', regex=True)\n",
    "                        #display(df_file)\n",
    "                        df_file = df_file.iloc[:,1:3]\n",
    "                        df_file[3] = dataset\n",
    "                        df = df.append(df_file)\n",
    "            for index, row in df.iterrows():\n",
    "                if row.iloc[1] == 'HOF': row.iloc[1] = '1'\n",
    "                elif row.iloc[1] == 'NOT': row.iloc[1] = '0'      \n",
    "            df = df.drop(0)\n",
    "            df = df.rename(columns={1: 0, 2: 1, 3: 2})\n",
    "            #display(df)\n",
    "            #df.to_csv(dataset_dir + dataset + \"_merged.csv\", sep =',')\n",
    "            if \"hasoc2019\" in dataset: \n",
    "                df_ha19 = df\n",
    "                return df_ha19\n",
    "            if \"hasoc2020\" in dataset: \n",
    "                df_ha20 = df\n",
    "                return df_ha20 \n",
    "    else:\n",
    "        print(\"This function can only preprocess HASOC datasets\")\n",
    "#preprocessHasoc(dataset)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f095a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e99a70db",
   "metadata": {},
   "source": [
    "### Preprocessing Polly Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304ed437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessPollyCorpus(dataset):\n",
    "    dataset_dir = data_dir + dataset + \"/\"\n",
    "    if \"polly\" in dataset:\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.read_csv(dataset_dir + \"hatespeech_polly.csv\", sep=',',header=None)\n",
    "        df = df.replace('\\n','', regex=True)\n",
    "        #display(df)\n",
    "        df = df.iloc[:,0:2]\n",
    "        df[1] = 1\n",
    "        df = df.drop(0)\n",
    "        df[2] = dataset\n",
    "        #display(df)\n",
    "        #df.to_csv(dataset_dir + dataset + \"_merged.csv\", sep =',')\n",
    "        return df\n",
    "    else:\n",
    "        print(\"This function can only preprocess the Polly Corpus!\")\n",
    "    \n",
    "    \n",
    "#preprocessPollyCorpus(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b2b51",
   "metadata": {},
   "source": [
    "### Preprocessing Refugee Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f7a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessRefugeeCorpus(dataset):\n",
    "    dataset_dir = data_dir + dataset + \"/\"\n",
    "    if \"refugee\" in dataset:\n",
    "        df = pd.DataFrame()\n",
    "        df = pd.read_csv(dataset_dir + \"hatespeech_refugees.csv\",sep=',',header=None)\n",
    "        #display(df)\n",
    "        df_new = pd.DataFrame()\n",
    "        for index, row in df.iterrows():\n",
    "            if row.iloc[1] == row.iloc[2]:\n",
    "                if row.iloc[1] == 'NO': row.iloc[1] = '0'\n",
    "                elif row.iloc[1] == 'YES': row.iloc[1] = '1'\n",
    "                df_new = df_new.append(row)\n",
    "        df_new = df_new.iloc[:,0:2]\n",
    "        df_new[2] = dataset\n",
    "        #display(df_new)\n",
    "        #df_new.to_csv(dataset_dir + dataset + \"_merged.csv\",sep = ',')\n",
    "        return df_new\n",
    "    else:\n",
    "        print(\"This function can only preprocess the Refugee Corpus!\")\n",
    "#preprocessRefugeeCorpus(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4538b37a",
   "metadata": {},
   "source": [
    "## Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40550e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge file: germeval2018_test.txt\n",
      "Merge file: germeval2018_training.txt\n",
      "Merge file: germeval2019_training_subtask12.txt\n",
      "Merge file: germeval2019GoldLabelsSubtask3.txt\n",
      "Merge file: germeval2019GoldLabelsSubtask1_2.txt\n",
      "Merge file: germeval2019_training_subtask3.txt\n",
      "Merge file: german_dataset.tsv\n",
      "Merge file: hasoc_de_test_gold.tsv\n",
      "Merge file: hasoc_2020_de_test_new.csv\n",
      "Merge file: hasoc_2020_de_train_new.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[                                                      0  1             2\n",
       " 0     Meine Mutter hat mir erzählt, dass mein Vater ...  0  germeval2018\n",
       " 1     @Tom174_ @davidbest95 Meine Reaktion; |LBR| Ni...  0  germeval2018\n",
       " 2     #Merkel rollt dem Emir von #Katar, der islamis...  0  germeval2018\n",
       " 3     „Merle ist kein junges unschuldiges Mädchen“ K...  0  germeval2018\n",
       " 4     @umweltundaktiv Asylantenflut bringt eben nur ...  1  germeval2018\n",
       " ...                                                 ... ..           ...\n",
       " 5004  Gegens. Zul. zu Patenamt &amp; gegenseitige An...  0  germeval2018\n",
       " 5005  @GlasenappHenrik Zu Merkel fällt mir nur ein, ...  1  germeval2018\n",
       " 5006  @KokoLores20 @krippmarie Ein richtiges Zeichen...  1  germeval2018\n",
       " 5007  @Hartes_Geld ,Honecker‘Merkel macht uns zur ,D...  1  germeval2018\n",
       " 5008  Warum wurden die G20-Chaoten nicht sofort auf ...  0  germeval2018\n",
       " \n",
       " [8534 rows x 3 columns],\n",
       "                                                       0  1             2\n",
       " 0     @jouwatch Hat die Polizei keine Kanone mehr ? ...  1  germeval2019\n",
       " 1     @de_sputnik @Saudi Arabien habt ihr mal wieder...  1  germeval2019\n",
       " 2     Glaube ich nicht , die Bundesregierung so wie ...  1  germeval2019\n",
       " 3      Doch schockierend viele Jugendliche wissen ka...  1  germeval2019\n",
       " 4     Sein Charakter war ihm wichtiger anstatt als b...  1  germeval2019\n",
       " ...                                                 ... ..           ...\n",
       " 1951  @Alltags_Kotze Dein Feminismus und Genderquats...  1  germeval2019\n",
       " 1952  @UdoUlfkotte Hauptsache den Asylanten gehts ge...  1  germeval2019\n",
       " 1953  @SteinbachErika Ich finde AFD Wähler besser al...  1  germeval2019\n",
       " 1954  @RKnillmann @lawyerberlin @AfD Aha, der Islam ...  1  germeval2019\n",
       " 1955  @podilein Mannheim, weltoffen und kunterbunt. ...  1  germeval2019\n",
       " \n",
       " [9911 rows x 3 columns],\n",
       "                                                      0  1          2\n",
       " 1    Frank Rennicke – Ich bin stolz https://t.co/Cm...  0  hasoc2019\n",
       " 2    ANSEHEN.....und danach bitte TEILEN...TEILEN.....  0  hasoc2019\n",
       " 3    #Koeln Mohamed erkennt kein deutsches Recht so...  0  hasoc2019\n",
       " 4    #SaudiArabien ist eine brutale islamische Dikt...  0  hasoc2019\n",
       " 5    Bundespolizei #München hat im 1. Quartal 2019 ...  0  hasoc2019\n",
       " ..                                                 ... ..        ...\n",
       " 846  #Erdogan ruft seine Mops wegen Untauglichkeit ...  1  hasoc2019\n",
       " 847  Ich würde der Linken Chefin Kipping die 1.000 ...  1  hasoc2019\n",
       " 848  Ausländer sind Top &amp; Trumpf  Schon aufgefa...  1  hasoc2019\n",
       " 849  Wie der Regierungsjet die Regierungsflieger wi...  1  hasoc2019\n",
       " 850  #guteMütter  sind heutzutage gut ausgebildete ...  0  hasoc2019\n",
       " \n",
       " [4669 rows x 3 columns],\n",
       "                                                       0  1          2\n",
       " 1     @zinobackspin Habe selten was dümmeres gelesen...  0  hasoc2020\n",
       " 2     @21withcon @NewHopeReece @TheVampsCon @corbynb...  0  hasoc2020\n",
       " 3     RT @helllud123: Die Zerstörerin Deutschlands v...  1  hasoc2020\n",
       " 4     Seit 20j werden über Bremehafen Afrikaner mit ...  0  hasoc2020\n",
       " 5     Welterbe Selous-Reservat: “1500 Quadratkilomet...  0  hasoc2020\n",
       " ...                                                 ... ..        ...\n",
       " 2369                        in conclusion, ich bin dumm  0  hasoc2020\n",
       " 2370  RT @chrisjuko: Mit viel Geld an die Macht #Sor...  0  hasoc2020\n",
       " 2371  @FritzAlter1 @MiriamOzen Ich habe den Eindruck...  0  hasoc2020\n",
       " 2372  RT @LucaBBM: Wieso hab ich immer Stress mit so...  1  hasoc2020\n",
       " 2373  RT @tschemal: Deutsche Depressionen https://t....  0  hasoc2020\n",
       " \n",
       " [3400 rows x 3 columns],\n",
       "                                                      0  1                    2\n",
       " 2    bitte nicht die #Türkei zum #EU-Mitglied mache...  0  hatespeech_refugees\n",
       " 3    Wieso bekommen #rapefugees mehr als unsere Har...  0  hatespeech_refugees\n",
       " 5    War das Wochenende im Ruhrpott unterwegs. Über...  1  hatespeech_refugees\n",
       " 6    #Asylanteninvasion Wenn es auf unseren Straßen...  0  hatespeech_refugees\n",
       " 7    745 Millionen Menschen leben in #Europa. Ca. 4...  0  hatespeech_refugees\n",
       " ..                                                 ... ..                  ...\n",
       " 463  Das gerechte in #Deutschland ist ja, dass nich...  0  hatespeech_refugees\n",
       " 464  #radikaler #Imam in #Dänemark ruft z #Steinigu...  0  hatespeech_refugees\n",
       " 466  Simone #Peter hat seit 7 Monaten und weit über...  0  hatespeech_refugees\n",
       " 468  #kipping ist so dumm! wenn #asylanten Wohnunge...  0  hatespeech_refugees\n",
       " 469  Zukünft. #CDU Wähler aus #MEA marodieren auf M...  1  hatespeech_refugees\n",
       " \n",
       " [369 rows x 3 columns],\n",
       "                                                        0  1      2\n",
       " 1                      Für Führer, Volk und Vaterland!!!  1  polly\n",
       " 2      @nameWarum stehe ich denn dafür?Ich Sage nicht...  1  polly\n",
       " 3      @name ich schreibe was ich will und was mir ge...  1  polly\n",
       " 4      Das Recht uns zu wehren nutzen wir und das nic...  1  polly\n",
       " 5      Kein Sieg ohne Kampf.Also Kameraden, lasst uns...  1  polly\n",
       " ...                                                  ... ..    ...\n",
       " 21131           RT @name: Urin wird im Hoden gespeichert  1  polly\n",
       " 21132  RT @name: Viele von denen, die sich jetzt über...  1  polly\n",
       " 21133  RT @name: Wenn eine Schule schon wegen der rel...  1  polly\n",
       " 21134  RT @news: Als Twitter @name sperrte, schwiegst...  1  polly\n",
       " 21135  Twitter sperrt uns gerade einige Accounts. Das...  1  polly\n",
       " \n",
       " [21135 rows x 3 columns]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df_germeval2018 = pd.read_csv(cwd + '/data/germeval2018/germeval2018_merged.csv', sep=',', header = 0)\n",
    "df_germeval2018 = preprocessGermEval(datasets[0])\n",
    "\n",
    "#df_germeval2019 = pd.read_csv(cwd + '/data/germeval2019/germeval2019_merged.csv', sep=',', header = 0)\n",
    "df_germeval2019 = preprocessGermEval(datasets[1])\n",
    "\n",
    "#df_hasoc2019 = pd.read_csv(cwd + '/data/hasoc2019/hasoc2019_merged.csv', sep=',', header = 0)\n",
    "df_hasoc2019 = preprocessHasoc(datasets[2],'\\t')\n",
    "\n",
    "#df_hasoc2020 = pd.read_csv(cwd + '/data/hasoc2020/hasoc2020_merged.csv', sep=',', header = 0)\n",
    "df_hasoc2020 = preprocessHasoc(datasets[3],';')\n",
    "\n",
    "#df_hatespeech_refugees = pd.read_csv(cwd + '/data/hatespeech_refugees/hatespeech_refugees_merged.csv', sep=',', header = 0)\n",
    "df_hatespeech_refugees = preprocessRefugeeCorpus(datasets[5])\n",
    "\n",
    "\n",
    "#df_polly = pd.read_csv(cwd + '/data/polly/polly_merged.csv', sep=',', header = 0)\n",
    "df_polly = preprocessPollyCorpus(datasets[4])\n",
    "\n",
    "df_datasets = [df_germeval2018,df_germeval2019,df_hasoc2019,df_hasoc2020,df_hatespeech_refugees,df_polly]\n",
    "\n",
    "display(df_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba191e",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Merge all Dataframes into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "565e13f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mergeDatasets(df_datasets):\n",
    "    df_all_datasets = pd.DataFrame()\n",
    "    for df in df_datasets:\n",
    "        df_all_datasets = df_all_datasets.append(df)    \n",
    "    df_all_datasets = df_all_datasets.reset_index()\n",
    "    df_all_datasets = df_all_datasets.drop(columns={\"index\"})\n",
    "    df_all_datasets = df_all_datasets.rename(columns={0:'text',1:'hate',2:'dataset'})\n",
    "    #df_all_datasets.to_csv(cwd + '/data/final_dataset.csv', sep=',')\n",
    "    #display(df_all_datasets)\n",
    "    return df_all_datasets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810b03af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = mergeDatasets(df_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2246d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f36f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"final_dataset.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57e35548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hate</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meine Mutter hat mir erzählt, dass mein Vater ...</td>\n",
       "      <td>0</td>\n",
       "      <td>germeval2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Tom174_ @davidbest95 Meine Reaktion; |LBR| Ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>germeval2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Merkel rollt dem Emir von #Katar, der islamis...</td>\n",
       "      <td>0</td>\n",
       "      <td>germeval2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>„Merle ist kein junges unschuldiges Mädchen“ K...</td>\n",
       "      <td>0</td>\n",
       "      <td>germeval2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@umweltundaktiv Asylantenflut bringt eben nur ...</td>\n",
       "      <td>1</td>\n",
       "      <td>germeval2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45126</th>\n",
       "      <td>RT @name: Urin wird im Hoden gespeichert</td>\n",
       "      <td>1</td>\n",
       "      <td>polly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45127</th>\n",
       "      <td>RT @name: Viele von denen, die sich jetzt über...</td>\n",
       "      <td>1</td>\n",
       "      <td>polly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45128</th>\n",
       "      <td>RT @name: Wenn eine Schule schon wegen der rel...</td>\n",
       "      <td>1</td>\n",
       "      <td>polly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45129</th>\n",
       "      <td>RT @news: Als Twitter @name sperrte, schwiegst...</td>\n",
       "      <td>1</td>\n",
       "      <td>polly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45130</th>\n",
       "      <td>Twitter sperrt uns gerade einige Accounts. Das...</td>\n",
       "      <td>1</td>\n",
       "      <td>polly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text hate       dataset\n",
       "0      Meine Mutter hat mir erzählt, dass mein Vater ...    0  germeval2018\n",
       "1      @Tom174_ @davidbest95 Meine Reaktion; |LBR| Ni...    0  germeval2018\n",
       "2      #Merkel rollt dem Emir von #Katar, der islamis...    0  germeval2018\n",
       "3      „Merle ist kein junges unschuldiges Mädchen“ K...    0  germeval2018\n",
       "4      @umweltundaktiv Asylantenflut bringt eben nur ...    1  germeval2018\n",
       "...                                                  ...  ...           ...\n",
       "45126           RT @name: Urin wird im Hoden gespeichert    1         polly\n",
       "45127  RT @name: Viele von denen, die sich jetzt über...    1         polly\n",
       "45128  RT @name: Wenn eine Schule schon wegen der rel...    1         polly\n",
       "45129  RT @news: Als Twitter @name sperrte, schwiegst...    1         polly\n",
       "45130  Twitter sperrt uns gerade einige Accounts. Das...    1         polly\n",
       "\n",
       "[45131 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d110d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
